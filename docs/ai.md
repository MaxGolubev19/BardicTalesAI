# ai.py

Этот модуль предоставляет класс `AI`, который управляет взаимодействием с различными нейросетевыми моделями (GPT, LLaMA, Gemini) через API OpenAI и Groq. Он позволяет формировать и отправлять запросы к нейросетям, а также логировать процесс генерации текста.

## Класс `AI`

### Атрибуты
- `gpt_model` – название модели GPT (используется через OpenAI API).
- `llama_model` – название модели LLaMA 3 (используется через Groq API).
- `gemini_model` – название модели Gemini (используется через Groq API).
- `current_model` – текущая выбранная модель (по умолчанию `gpt_model`).

### Методы

#### `get() -> tuple`
Возвращает API-клиент, название модели и API-ключ в зависимости от текущей выбранной модели.

---

#### `generateText(messages: list, logInfo: str) -> str`
Асинхронно отправляет запрос в выбранную нейросетевую модель и получает сгенерированный ответ.

---

#### `format(content: str, role: str) -> dict`
Форматирует сообщение в виде словаря, совместимого с API нейросетевых моделей.

